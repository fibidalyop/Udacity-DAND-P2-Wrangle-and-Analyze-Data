{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I gathered data from 3 different sources using three diffferent methods:\n",
    "\n",
    "- The WeRateDogs Twitter archive; Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)\n",
    "\n",
    "- The tweet image predictions; Using the Requests library to download the tweet image prediction (image_predictions.tsv)\n",
    "\n",
    "- Tweeter API. Using Tweepy; Using the Tweepy library to query additional data via the Twitter API (tweet_json.txt). I added extracted three columns:\n",
    "        retweet count\n",
    "        favorite count\n",
    "        Full text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assesing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assessed the three gathered datasets individually for quality and tidiness issues and the following was deduced:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There are inconsistences in the naming of dogs, It appears that dog names were retrieved from the \"text\" column from statments like \"this is ...\" what ever appears after \"is\" is taken as the dog name, hence the reason we have names like \"a, the\",\"infuriating\" etc\n",
    "\n",
    "2. There are alot lot of missing data labelled as \"None\", in the \"name\", \"doggo\", \"floofer\", \"pupper\" and \"puppo\" columns. for example, There are 745 dogs with the name \"None\"\n",
    "\n",
    "3. The timestamp datatype is incorrect\n",
    "\n",
    "4. There are a few records with rating_denominators not equal to 10, by manually reading their text, I discovered that some of these ratings are actually valid, while some are invalid, therefore both numerator and denominator ratings of invalid entries will be corrected\n",
    "\n",
    "5. Columns such as \"in_reply_to_status_id\", \"in_reply_to_user_id\", contain too many null values, should be dropped\n",
    "\n",
    "6. The tweet source contain the direct source (eg, iphone for twitter, tweetdeck etc) wrapped within the url. They column should be pared to show just the direcct source.\n",
    "\n",
    "7. Irregular casing in columns p1,p2, and p3 some have camel cases while others have lower casing\n",
    "\n",
    "8. Drop \"text\" column, since we now have a \"full_text\" column from the twitter API data\n",
    "\n",
    "9. Non-null retweet rows, from 3 retweet columns in the dataframe were found,this essentially duplicates the actual tweets and so they may skew the result of the analysis, both columns and rows will be dropped\n",
    "\n",
    "10. The 3 retweet columns (\"retweeted_status_id\", \"retweeted_status_timestamp\", \"retweeted_status_user_id\"), whose non-null rows are removed from above will be left with only null values in their columns. Drop columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Tidiness Issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The three dataset contain information about one observational unit. They should be merged into one, as they are part of the same observational unit\n",
    "2. The dog stages are spread into four columns. They should be put into one column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First I merged the three datasets into one, using an inner join, on the tweet_id column and saved it into a variable \"full_df\"\n",
    "2. I then made a copy of \"full_df\", so as to perform my cleaning processes\n",
    "3. I replace values labelled as \"None\" with NaN\n",
    "4. Convert timestamp to datetime dataype\n",
    "5. Ensure that all rating_denominators equals 10\n",
    "6. Drop columns with very high null values\n",
    "7. convert columns values of p1,p2, and p3 to lower case\n",
    "8. Merged \"doggo\", \"puppo\", \"floofer\" and \"puppo\" columns into one column called \"stages\"\n",
    "9. Dropped \"doggo\", \"puppo\", \"floofer\" and \"puppo\" columns\n",
    "10. Made sure I tested after every code of cleaning\n",
    "11. Saved my cleaned dataset into a csv file named \"twitter_archive_master.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
